{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Code from https://machinelearningmastery.com/develop-character-based-neural-language-model-keras/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "import collections\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r', encoding = 'utf8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_filename = 'Data/GlobalVoices_en.txt'\n",
    "raw_text = load_doc(in_filename)\n",
    "raw_text = raw_text.lower()\n",
    "lines = raw_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of characters\n",
    "length = 10\n",
    "sequences = list()\n",
    "k = 0\n",
    "j = 0\n",
    "for line in lines: \n",
    "    if j < 25000:\n",
    "        k += 1\n",
    "        if line[-1:] == '.' or line[-1:] == '?' or line[-1:] == '!' or line[-1:] == '\"':\n",
    "            j += 1\n",
    "            for i in range(length, len(line)):\n",
    "                seq = raw_text[i-length:i+1]\n",
    "                sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_filename = 'char_sequences.txt'\n",
    "#save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33485\n",
      "25000\n",
      "2847853\n"
     ]
    }
   ],
   "source": [
    "print(k)\n",
    "print(j)\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Original Corpus: 979735\n",
      "Length of Tokenized Sequences in LM Corpus: 2847853\n",
      "Sentence line we stop at: 33485\n",
      "Number of Sentences in our dataset: 25000\n"
     ]
    }
   ],
   "source": [
    "print('Length of Original Corpus: %s' % len(lines))\n",
    "print('Length of Tokenized Sequences in LM Corpus: %s' % len(sequences))\n",
    "print('Sentence line we stop at: %s' % k)\n",
    "print('Number of Sentences in our dataset: %s' % j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = list()\n",
    "for row in sequences:\n",
    "    # integer encode line\n",
    "    encoded_seq = [mapping[char] for char in row]\n",
    "    # store\n",
    "    encoded_sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 3338\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(mapping)\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[46, 44, 54, 57, 46, 48, 40, 1, 13, 1, 57],\n",
       " [44, 54, 57, 46, 48, 40, 1, 13, 1, 57, 60],\n",
       " [54, 57, 46, 48, 40, 1, 13, 1, 57, 60, 58],\n",
       " [57, 46, 48, 40, 1, 13, 1, 57, 60, 58, 58],\n",
       " [46, 48, 40, 1, 13, 1, 57, 60, 58, 58, 48],\n",
       " [48, 40, 1, 13, 1, 57, 60, 58, 58, 48, 40],\n",
       " [40, 1, 13, 1, 57, 60, 58, 58, 48, 40, 1],\n",
       " [1, 13, 1, 57, 60, 58, 58, 48, 40, 1, 27],\n",
       " [13, 1, 57, 60, 58, 58, 48, 40, 1, 27, 1],\n",
       " [1, 57, 60, 58, 58, 48, 40, 1, 27, 1, 59],\n",
       " [57, 60, 58, 58, 48, 40, 1, 27, 1, 59, 47],\n",
       " [60, 58, 58, 48, 40, 1, 27, 1, 59, 47, 44],\n",
       " [58, 58, 48, 40, 1, 27, 1, 59, 47, 44, 1],\n",
       " [58, 48, 40, 1, 27, 1, 59, 47, 44, 1, 53],\n",
       " [48, 40, 1, 27, 1, 59, 47, 44, 1, 53, 40],\n",
       " [40, 1, 27, 1, 59, 47, 44, 1, 53, 40, 52],\n",
       " [1, 27, 1, 59, 47, 44, 1, 53, 40, 52, 44],\n",
       " [27, 1, 59, 47, 44, 1, 53, 40, 52, 44, 58],\n",
       " [1, 59, 47, 44, 1, 53, 40, 52, 44, 58, 1],\n",
       " [59, 47, 44, 1, 53, 40, 52, 44, 58, 1, 54],\n",
       " [47, 44, 1, 53, 40, 52, 44, 58, 1, 54, 45],\n",
       " [44, 1, 53, 40, 52, 44, 58, 1, 54, 45, 1],\n",
       " [1, 53, 40, 52, 44, 58, 1, 54, 45, 1, 59],\n",
       " [53, 40, 52, 44, 58, 1, 54, 45, 1, 59, 47],\n",
       " [40, 52, 44, 58, 1, 54, 45, 1, 59, 47, 44],\n",
       " [52, 44, 58, 1, 54, 45, 1, 59, 47, 44, 1],\n",
       " [44, 58, 1, 54, 45, 1, 59, 47, 44, 1, 43],\n",
       " [58, 1, 54, 45, 1, 59, 47, 44, 1, 43, 44],\n",
       " [1, 54, 45, 1, 59, 47, 44, 1, 43, 44, 40],\n",
       " [54, 45, 1, 59, 47, 44, 1, 43, 44, 40, 43],\n",
       " [45, 1, 59, 47, 44, 1, 43, 44, 40, 43, 1],\n",
       " [1, 59, 47, 44, 1, 43, 44, 40, 43, 1, 95],\n",
       " [59, 47, 44, 1, 43, 44, 40, 43, 1, 95, 1],\n",
       " [47, 44, 1, 43, 44, 40, 43, 1, 95, 1, 46],\n",
       " [44, 1, 43, 44, 40, 43, 1, 95, 1, 46, 51],\n",
       " [1, 43, 44, 40, 43, 1, 95, 1, 46, 51, 54],\n",
       " [43, 44, 40, 43, 1, 95, 1, 46, 51, 54, 41],\n",
       " [44, 40, 43, 1, 95, 1, 46, 51, 54, 41, 40],\n",
       " [40, 43, 1, 95, 1, 46, 51, 54, 41, 40, 51],\n",
       " [43, 1, 95, 1, 46, 51, 54, 41, 40, 51, 1],\n",
       " [1, 95, 1, 46, 51, 54, 41, 40, 51, 1, 61],\n",
       " [95, 1, 46, 51, 54, 41, 40, 51, 1, 61, 54],\n",
       " [1, 46, 51, 54, 41, 40, 51, 1, 61, 54, 48],\n",
       " [46, 51, 54, 41, 40, 51, 1, 61, 54, 48, 42],\n",
       " [51, 54, 41, 40, 51, 1, 61, 54, 48, 42, 44],\n",
       " [54, 41, 40, 51, 1, 61, 54, 48, 42, 44, 58],\n",
       " [41, 40, 51, 1, 61, 54, 48, 42, 44, 58, 0],\n",
       " [40, 51, 1, 61, 54, 48, 42, 44, 58, 0, 40],\n",
       " [51, 1, 61, 54, 48, 42, 44, 58, 0, 40, 53],\n",
       " [1, 61, 54, 48, 42, 44, 58, 0, 40, 53, 1],\n",
       " [61, 54, 48, 42, 44, 58, 0, 40, 53, 1, 54],\n",
       " [54, 48, 42, 44, 58, 0, 40, 53, 1, 54, 53],\n",
       " [48, 42, 44, 58, 0, 40, 53, 1, 54, 53, 46],\n",
       " [42, 44, 58, 0, 40, 53, 1, 54, 53, 46, 54],\n",
       " [44, 58, 0, 40, 53, 1, 54, 53, 46, 54, 48],\n",
       " [58, 0, 40, 53, 1, 54, 53, 46, 54, 48, 53],\n",
       " [0, 40, 53, 1, 54, 53, 46, 54, 48, 53, 46],\n",
       " [40, 53, 1, 54, 53, 46, 54, 48, 53, 46, 1],\n",
       " [53, 1, 54, 53, 46, 54, 48, 53, 46, 1, 48],\n",
       " [1, 54, 53, 46, 54, 48, 53, 46, 1, 48, 53],\n",
       " [54, 53, 46, 54, 48, 53, 46, 1, 48, 53, 48],\n",
       " [53, 46, 54, 48, 53, 46, 1, 48, 53, 48, 59],\n",
       " [46, 54, 48, 53, 46, 1, 48, 53, 48, 59, 48],\n",
       " [54, 48, 53, 46, 1, 48, 53, 48, 59, 48, 40],\n",
       " [48, 53, 46, 1, 48, 53, 48, 59, 48, 40, 59],\n",
       " [53, 46, 1, 48, 53, 48, 59, 48, 40, 59, 48],\n",
       " [46, 1, 48, 53, 48, 59, 48, 40, 59, 48, 61],\n",
       " [1, 48, 53, 48, 59, 48, 40, 59, 48, 61, 44],\n",
       " [48, 53, 48, 59, 48, 40, 59, 48, 61, 44, 1],\n",
       " [53, 48, 59, 48, 40, 59, 48, 61, 44, 1, 9],\n",
       " [48, 59, 48, 40, 59, 48, 61, 44, 1, 9, 1],\n",
       " [59, 48, 40, 59, 48, 61, 44, 1, 9, 1, 57],\n",
       " [48, 40, 59, 48, 61, 44, 1, 9, 1, 57, 60],\n",
       " [40, 59, 48, 61, 44, 1, 9, 1, 57, 60, 58],\n",
       " [59, 48, 61, 44, 1, 9, 1, 57, 60, 58, 1],\n",
       " [48, 61, 44, 1, 9, 1, 57, 60, 58, 1, 10],\n",
       " [61, 44, 1, 9, 1, 57, 60, 58, 1, 10, 1],\n",
       " [44, 1, 9, 1, 57, 60, 58, 1, 10, 1, 59],\n",
       " [1, 9, 1, 57, 60, 58, 1, 10, 1, 59, 54],\n",
       " [9, 1, 57, 60, 58, 1, 10, 1, 59, 54, 1],\n",
       " [1, 57, 60, 58, 1, 10, 1, 59, 54, 1, 42],\n",
       " [57, 60, 58, 1, 10, 1, 59, 54, 1, 42, 54],\n",
       " [60, 58, 1, 10, 1, 59, 54, 1, 42, 54, 52],\n",
       " [58, 1, 10, 1, 59, 54, 1, 42, 54, 52, 55],\n",
       " [1, 10, 1, 59, 54, 1, 42, 54, 52, 55, 48],\n",
       " [10, 1, 59, 54, 1, 42, 54, 52, 55, 48, 51],\n",
       " [1, 59, 54, 1, 42, 54, 52, 55, 48, 51, 44],\n",
       " [59, 54, 1, 42, 54, 52, 55, 48, 51, 44, 1],\n",
       " [54, 1, 42, 54, 52, 55, 48, 51, 44, 1, 40],\n",
       " [1, 42, 54, 52, 55, 48, 51, 44, 1, 40, 1],\n",
       " [42, 54, 52, 55, 48, 51, 44, 1, 40, 1, 51],\n",
       " [54, 52, 55, 48, 51, 44, 1, 40, 1, 51, 48],\n",
       " [52, 55, 48, 51, 44, 1, 40, 1, 51, 48, 58],\n",
       " [55, 48, 51, 44, 1, 40, 1, 51, 48, 58, 59],\n",
       " [48, 51, 44, 1, 40, 1, 51, 48, 58, 59, 1],\n",
       " [51, 44, 1, 40, 1, 51, 48, 58, 59, 1, 54],\n",
       " [44, 1, 40, 1, 51, 48, 58, 59, 1, 54, 45],\n",
       " [1, 40, 1, 51, 48, 58, 59, 1, 54, 45, 1],\n",
       " [40, 1, 51, 48, 58, 59, 1, 54, 45, 1, 3],\n",
       " [1, 51, 48, 58, 59, 1, 54, 45, 1, 3, 1]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "encoded_sequences = np.array(encoded_sequences) #, shape = (len(sequences),length))\n",
    "X, y = encoded_sequences[:,:-1], encoded_sequences[:,-1]\n",
    "new_sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.array(new_sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2847853, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57, 60, 58, ..., 48, 59, 57])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-880b6a3edadb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlu\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, implementation, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[0;32m   2140\u001b[0m                                    \u001b[0mstateful\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m                                    \u001b[0munroll\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munroll\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m                                    **kwargs)\n\u001b[0m\u001b[0;32m   2143\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlu\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m                              \u001b[1;34m'(tuple of integers, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                              'one integer per RNN state).')\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                 \u001b[0mbatch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_shape'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(X.shape[1])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
