{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Func: splits sequence by whitespace\n",
    "    Params: \n",
    "        string = sequence of text\n",
    "    Returns:\n",
    "        sequence that is split\n",
    "'''\n",
    "def preprocess(string):\n",
    "    return string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Func: takes text file and splits each sentence into n-grams\n",
    "    Params:\n",
    "        filename = name of text file\n",
    "        character_level = True then character-level n-grams, False hten word-level n-grams\n",
    "        n = n-gram size\n",
    "        path = path to save dataframe\n",
    "    Returns:\n",
    "        dataset = [list of all n-grams in text; next word corresponding to each n-gram; posn of n-gram in sentence]\n",
    "'''\n",
    "def get_ngrams(filename, character_level, n, path, num_of_sentences):\n",
    "    sentences = []\n",
    "    all_ngrams = []\n",
    "    j = 0\n",
    "    with open(filename, 'r', encoding = 'utf8') as corpus:\n",
    "        for line in corpus:\n",
    "            ngrams_list = []\n",
    "            \n",
    "            if j % 1000 == 0:\n",
    "                print(j)        \n",
    "            \n",
    "            if line[-2:-1] == '.' or line[-2:-1] == '?' or line[-2:-1] == '!':\n",
    "                line = line.lower() # Converts sentence to lowercase\n",
    "                if character_level == True:\n",
    "                    sequence = [chars for chars in line]\n",
    "                    sequence = sequence[:-1]\n",
    "                    \n",
    "                else:\n",
    "                    sequence = preprocess(line) # Separates sequence by whitespace\n",
    "                \n",
    "                sentence_ngrams = ngrams(sequence, n) # Break sequence into individual n-grams\n",
    "                for grams in sentence_ngrams:\n",
    "                    ngrams_list.append(grams)\n",
    "                    \n",
    "                sentences.append(sequence)\n",
    "                all_ngrams.append(ngrams_list)\n",
    "                \n",
    "            else:\n",
    "                pass \n",
    "            \n",
    "            if j % 10000 == 0:\n",
    "                temp_dataset = pd.DataFrame()\n",
    "                temp_dataset['Sentence'] = sentences\n",
    "                temp_dataset[str(n)+'-grams'] = all_ngrams\n",
    "                temp_dataset.to_csv(path)\n",
    "            \n",
    "            j += 1\n",
    "            \n",
    "            if j > num_of_sentences:\n",
    "                break\n",
    "            \n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['Original_Sentence'] = sentences\n",
    "    dataset[str(n)+'-grams'] = all_ngrams\n",
    "    dataset.to_csv(path)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'Data/test_en.txt'\n",
    "filename = 'Data/GlobalVoices_en.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\nlu\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "char_3grams = get_ngrams(filename=filename, \n",
    "                         character_level=True, \n",
    "                         n=3, \n",
    "                         path='Ngrams/en_word_3grams.csv', \n",
    "                         num_of_sentences=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcabc\n",
      "abcaba\n",
      "ababca\n",
      "ababab\n",
      "bcabca\n",
      "bcabab\n",
      "babcab\n",
      "bababc\n",
      "bababa\n",
      "cabcab\n",
      "cababc\n",
      "cababa\n"
     ]
    }
   ],
   "source": [
    "# Does not fully work for our purpose but is a good starting point\n",
    "\n",
    "def buildgraph(input, n):\n",
    "    # n-1-gram to tokens that follow it\n",
    "    graph = {\n",
    "        tuple(input[i:(i + n - 1)]): set()\n",
    "        for i in range(len(input) - n + 1)\n",
    "    }\n",
    "    for i in range(len(input) - n + 1):\n",
    "        graph[tuple(input[i:(i + n - 1)])].add(input[i + n - 1])\n",
    "    return graph\n",
    "\n",
    "\n",
    "def continuations(graph, n, k, pathsofar):\n",
    "    if len(pathsofar) == k:\n",
    "        yield pathsofar\n",
    "    elif len(pathsofar) < k:\n",
    "        for token in graph[pathsofar[-(n - 1):]]:\n",
    "            yield from continuations(graph, n, k, pathsofar + (token, ))\n",
    "\n",
    "\n",
    "def allsentences(input, n, k):\n",
    "    graph = buildgraph(input, n)\n",
    "    for ngram in graph:\n",
    "        yield from continuations(graph, n, k, ngram)\n",
    "\n",
    "for sent in allsentences('abcaba', 2, 6):\n",
    "    print(''.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_3grams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-acc5c1e2f491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original Length of sentence broken up into char-level 3-grams: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_3grams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3-grams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unique number of char-level 3-grams in sentence: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_3grams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3-grams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mctr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_3grams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3-grams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print('Frequency of elements in the char-level 3-gram list: ', ctr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'char_3grams' is not defined"
     ]
    }
   ],
   "source": [
    "print('Original Length of sentence broken up into char-level 3-grams: %s' % len(char_3grams['3-grams'][0]))\n",
    "print('Unique number of char-level 3-grams in sentence: %s' % len(set(char_3grams['3-grams'][0])))\n",
    "\n",
    "ctr = collections.Counter(char_3grams['3-grams'][0])\n",
    "#print('Frequency of elements in the char-level 3-gram list: ', ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
